{
  "cells": [
    {
      "cell_type": "raw",
      "id": "f098f1a3",
      "metadata": {},
      "source": [
        "---\n",
        "title: Homework-2\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    self-contained: true\n",
        "    code-fold: false\n",
        "    output-file: Homework-02.html\n",
        "    embed-resources: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2130b3e9",
      "metadata": {},
      "source": [
        "`ANN training in Keras or Pytorch & Hyper-parameter tuning`\n",
        "\n",
        "## Overview\n",
        "\n",
        "* Classification is one of the most common forms of supervised machine learning\n",
        "* In this homework we will explore \"model tuning\" for the case of a multi-class classification problem, as applied the MNIST data set\n",
        "* `You can do this assignment in either Keras OR PyTorch` (or both), it is your choice.\n",
        "\n",
        "## Submission\n",
        "\n",
        "* You need to upload TWO documents to Canvas when you are done\n",
        "  * (1) A PDF (or HTML) of the completed form of the `HW-2.ipynb` document\n",
        "* The final uploaded version should NOT have any code-errors present\n",
        "* All outputs must be visible in the uploaded version, including code-cell outputs, images, graphs, etc\n",
        "\n",
        "`IMPORTANT`: THERE ARE MANY WAYS TO DO THIS, SO FEEL FREE TO DEVIATE SLIGHTLY FROM THE EXACT DETAILS, BUT THE OVERALL RESULT AND FLOW SHOULD MATCH WHAT IS OUTLINED BELOW.\n",
        "\n",
        "\n",
        "### quick question\n",
        "\n",
        "The submission details say we need to upload two documents but then only list one? is the pdf/html as well as the ipynb?\n",
        "\n",
        "## HW-2.1: Data preparation\n",
        "\n",
        "* Normalize the data as needed\n",
        "* Partition data into training, validation, and test (i.e. leave one out CV)\n",
        "  * One option to do this is to give these arrays global scope so they are seen inside the training function (so they don't need to be passed to functions)\n",
        "* **Optional but recommended:** Create a K-fold cross validation data set, rather than just doing leave one out\n",
        "* Do any other preprocessing you feel is needed\n",
        "\n",
        "### Using Fashion MNIST\n",
        "\n",
        "99.999% sure Dr. Hickman said it was ok to use Fashion MNIST instead of regular MNIST, which I will be doing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1ce2589",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45dd5ac",
      "metadata": {},
      "source": [
        "Normalizing the data below using ToTensor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3968cdd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "class_names = train_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "131222fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ],
      "source": [
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b73828a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length Train: 60000\n",
            "Length Test: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f'Length Train: {len(train_data)}')\n",
        "print(f'Length Test: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "db7d3691",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = .9 * len(train_data)\n",
        "val_size = len(train_data) - train_size\n",
        "\n",
        "#make val 10% of train\n",
        "train_data, val_data = random_split(train_data, lengths=[.9, .1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbd3e27",
      "metadata": {},
      "source": [
        "Little heavy on the test data, so I went with just 10% of the traing data for validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cb935aa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length Train: 54000\n",
            "Length Val: 6000\n"
          ]
        }
      ],
      "source": [
        "print(f'Length Train: {len(train_data)}')\n",
        "print(f'Length Val: {len(val_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e9843ca8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x1867aa25ed0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x1867aa1bc90>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x1867aa26910>)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "val_dataloader = DataLoader(dataset=val_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ef9fe2ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "be8c2823",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f2453c",
      "metadata": {},
      "source": [
        "Doing some visualization and shape printing below to make sure is loaded as expected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "90431537",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "train_samples = []\n",
        "train_labels = []\n",
        "\n",
        "val_samples = []\n",
        "val_labels = []\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(train_data), k=3):\n",
        "  train_samples.append(sample)\n",
        "  train_labels.append(label)\n",
        "\n",
        "for sample, label in random.sample(list(val_data), k=3):\n",
        "  val_samples.append(sample)\n",
        "  val_labels.append(label)\n",
        "\n",
        "for sample, label in random.sample(list(test_data), k=3):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4f3ea6d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train length: 3\n",
            "val shape 0: torch.Size([1, 28, 28])\n",
            "test shape 2: torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(f'train length: {len(train_samples)}')\n",
        "print(f'val shape 0: {val_samples[0].shape}')\n",
        "print(f'test shape 2: {test_samples[2].shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6204e5af",
      "metadata": {},
      "source": [
        "Going to do a little visualization just to make sure the data is how I expect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b6a59e54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sandal')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.imshow(train_samples[0].squeeze(), cmap='gray')\n",
        "plt.title(class_names[train_labels[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7d25f8b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Dress')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(val_samples[0].squeeze(), cmap='gray')\n",
        "plt.title(class_names[val_labels[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2daa573b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'T-shirt/top')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap='gray')\n",
        "plt.title(class_names[test_labels[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56280d6f",
      "metadata": {},
      "source": [
        "## HW-2.2: Generalized model\n",
        "\n",
        "* Create a `General` model function (or class) that takes hyper-parameters and evaluates the model\n",
        "  * The function should work with a set of hyper parameters than can be easily be controlled and varied by the user (for later parameter tuning)\n",
        "  * This should work for the training, test, and validation set\n",
        "* Feel free to recycle code from the lab assignments and demo's  \n",
        "* Use the deep learning best practices that we discussed in class.\n",
        "* Document what is going on in the code, as needed, with narrative markdown text between cells.\n",
        "\n",
        "Going to use a resnet like architecture for the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e4b52f22",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, dropout=0.15, padding=1, activation='relu'):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        if activation == 'relu':\n",
        "          self.activation = nn.ReLU(inplace=True)\n",
        "        elif activation == 'sigmoid':\n",
        "          self.activation = nn.Sigmoid()\n",
        "        elif activation == 'tanh':\n",
        "          self.activation = nn.Tanh()\n",
        "        else:\n",
        "          print(f'Activation Given: {activation}')\n",
        "          print(type(activation))\n",
        "          raise ValueError(\"Activation Function Must Be relu or sigmoid\")\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=padding, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        shortcut = self.shortcut(x)\n",
        "\n",
        "        out += shortcut\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FashionMNISTResNet(nn.Module):\n",
        "    def __init__(self, input_shape, channels, output_shape, num_layers, activation='relu', dropout=.15):\n",
        "        super().__init__()\n",
        "        self.activation = nn.ReLU(inplace=True) if activation == 'relu' else nn.Sigmoid() if activation == 'sigmoid' else nn.Tanh()\n",
        "\n",
        "        #init the layers with conv2d and batchnorm2d\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Conv2d(input_shape, channels[0], kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(channels[0]),\n",
        "            self.activation,\n",
        "            nn.Dropout(p=dropout)\n",
        "        ])\n",
        "\n",
        "        #add in resblocks\n",
        "        for i in range(num_layers):\n",
        "            self.layers.append(BasicResBlock(channels[i], channels[min(i+1, len(channels)-1)], activation=activation, dropout=dropout))\n",
        "            if i < len(channels) - 1:\n",
        "                self.layers.append(nn.Conv2d(channels[i], channels[i+1], kernel_size=3, stride=2, padding=1))\n",
        "                self.layers.append(nn.BatchNorm2d(channels[i+1]))\n",
        "                self.layers.append(self.activation)\n",
        "                self.layers.append(nn.Dropout(p=dropout))\n",
        "\n",
        "        #global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        #final linear layer\n",
        "        self.linear = nn.Linear(channels[-1], output_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)  #apply global average pooling\n",
        "        x = x.view(x.size(0), -1)  #flatten\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fb0aaf",
      "metadata": {},
      "source": [
        "## HW-2.3: Model training function\n",
        "\n",
        "* You can do this in either a function (or python class), or however you think is best.\n",
        "* **Create a training function** (or class) that takes hyper-parameter choices and trains the model\n",
        "  * If you are doing \"leave one out\", your training function only needs to do one training per hyper-parameter choice\n",
        "  * If you are doing K-fold cross validation, you should train the model K times for each hyper-parameter choice, and report the average result cross the training runs at the end (this is technically a better practice but requires more computation).\n",
        "  * Use a dense feed forward ANN model, with the correct output layer activation, and correct loss function\n",
        "  * `You MUST use early stopping` inside the function, otherwise it defeats the point\n",
        "  * **Have at least the following hyper-parameters as inputs to this function**\n",
        "    * L1 regularization constant, L2 regularization constant, dropout rate\n",
        "    * Learning rate\n",
        "    * Weight Initialization: Fully random vs Xavier Weight Initialization\n",
        "    * Hidden layer activation function choice (use relu, sigmoid, or tanh)\n",
        "    * Number and size of ANN hidden layers\n",
        "    * Optimizer choice, have at least three included (Adam, SGD, or RmsProp)\n",
        "    * You can wrap all of the hyper-parameter arguments into a dictionary, or do it however you want  \n",
        "  * **Visualization**\n",
        "    * Include a boolean parameter as a function input that controls whether visualization is created or not\n",
        "    * If `true`, Monitor training and validation throughout training by plotting\n",
        "    * Report a confusion matrix\n",
        "  * Return the final training and validation error (averaged if using K-fold)\n",
        "    * again, you must use early stopping to report the best training/validation loss without over-fitting\n",
        "* Depending how you do this, it can be a lot of computation, start small and scale up and consider using Co-lab\n",
        "  \n",
        "\n",
        "Performed 2.3 as a function. All of the mentioned hyperparameters are adjusted during the hyperparameter training below. Also, with Dr Hickman saying we could use fashion MNIST rather than just MNIST I thought it made more sense to use a cnn rather than just a dense feed forward ANN and that it would still acomplish the learning objectives. Additionally, I'm interested in computer vision problems and wanted to take the chance to better understand CNN architectures. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "21805fee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def train_model(model, dataloaders, criterion, num_epochs, optimizer='adam', early_stopping_patience=10, visualize=True, l1_strength=0.0, l2_strength=0.0, lr=0.001, init_type='random'):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optimizer.lower()\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer\")\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0  #early stopping counter\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    best_confusion_matrix = None\n",
        "    best_train_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch % 10 == 0:\n",
        "          print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "          print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            my_labels, my_preds = [], []\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                #zero the gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                #forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    #add in l1 and l2 regularization\n",
        "                    if l1_strength > 0:\n",
        "                        l1_regularization = torch.tensor(0., requires_grad=True).to(device)\n",
        "                        for param in model.parameters():\n",
        "                            l1_regularization = l1_regularization + torch.norm(param, 1)\n",
        "                        loss += l1_strength * l1_regularization\n",
        "                    \n",
        "                    if l2_strength > 0:\n",
        "                        l2_regularization = torch.tensor(0., requires_grad=True).to(device)\n",
        "                        for param in model.parameters():\n",
        "                            l2_regularization = l2_regularization + torch.norm(param, 2)\n",
        "                        loss += l2_strength * l2_regularization\n",
        "\n",
        "                    #backward and optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                my_labels.extend(labels.cpu().numpy())\n",
        "                my_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            if epoch % 10 == 0:\n",
        "              print(f'{phase} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "            #deep copy the model and implement early stopping\n",
        "            if phase == 'val':\n",
        "                val_losses.append(epoch_loss)\n",
        "\n",
        "                if epoch_loss < best_val_loss:\n",
        "                    best_val_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    epochs_no_improve = 0\n",
        "                    best_confusion_matrix = confusion_matrix(my_labels, my_preds)\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "            else:\n",
        "                train_losses.append(epoch_loss)\n",
        "                if epoch_loss < best_train_loss:\n",
        "                  best_train_loss = epoch_loss\n",
        "\n",
        "        if epochs_no_improve >= early_stopping_patience:\n",
        "            print(\"Stopping Early\")\n",
        "            break\n",
        "\n",
        "    if visualize:\n",
        "        plt.plot(train_losses, label='Training loss')\n",
        "        plt.plot(val_losses, label='Validation loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Training with Learning Rate {lr} and Initialization {init_type}')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    print(best_confusion_matrix)\n",
        "    return model, best_train_loss, best_val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f4300d",
      "metadata": {},
      "source": [
        "## HW-2.4: Hyper-parameter tuning\n",
        "\n",
        "* Keep detailed records of hyper-parameter choices and associated training & validation errors\n",
        "* Think critically and visualize the results of the search as needed\n",
        "\n",
        "* **Do each of these in a different sub-section of your notebook**\n",
        "  \n",
        "* **Explore hyper-parameter choice-0**\n",
        "  * for hidden activation=Relu, hidden layers = [32,32], optimizer=adam\n",
        "  * Vary the learning rate via a grid search pattern\n",
        "  * Plot training and validation error as a function of the learning rate\n",
        "  * Repeat this exercise for both random and Xavier weight initialization\n",
        "\n",
        "* **Explore hyper-parameter choice-1**\n",
        "  * for hidden activation=relu, hidden layers = [64,64], optimizer=adam\n",
        "  * Vary L1 and L2 in a 10x10 grid search (without dropout)\n",
        "  * Plot validation and training error as a function of L1 and L2 regularization in a 2D heatmap\n",
        "  * Plot the ratio (or difference) of validation to training error as a function of L1 and L2 regularization in a 2D heatmap\n",
        "\n",
        "* **Explore hyper-parameter choice-2**\n",
        "  * for hidden activation=sigmoid, hidden layers = [96,96,96], optimizer=**rmsprop**\n",
        "  * Vary drop-out parameter in a 1x10 grid search (without L1 or L2 regularization)\n",
        "  * Plot training and validation error as a function of dropout rate  \n",
        "  * Plot the ratio (or difference) of validation to training error as a function of dropout rate  \n",
        "\n",
        "* **Explore hyper-parameter choice-3:**\n",
        "  * for hidden activation=relu, hidden layers = [96,96,96], optimizer=**adam**\n",
        "  * Vary drop-out parameter in a 1x10 grid search (without L1 or L2 regularization)\n",
        "  * Plot training and validation as a function of dropout rate  \n",
        "  * Plot the ratio (or difference) of validation to training error as a function of dropout rate  \n",
        "\n",
        "* `Optional` Systematically search for the best regularization parameters choice (3D search) using random search algorithm\n",
        "  * (https://en.wikipedia.org/wiki/Random_search)[https://en.wikipedia.org/wiki/Random_search]\n",
        "  * Try to see how deep you can get the ANN (max hidden layers) without suffering from the vanishing gradient effect  \n",
        "  \n",
        "* `Final fit`\n",
        "  * At the very end, select a best fit model and report, training, validation, and test errors at the very end\n",
        "  * Make sure your \"plotting variable=True\" when for the final training\n",
        "  \n",
        "\n",
        "Hyperparameter Choice 0\n",
        "\n",
        "Notes: I started with more learning rates, but eventually narrowed it down to these 3 to save time. The epochs are higher on this run because I want to give some of the smaller learning rates a chance to converge. I like the learning rate 0.0001 for this portion because it does converges in a timely manner while remaining stable. Additionally, I didnt see a huge difference between random and xavier initialization, but I think xavier performed slighly better. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "602bcc9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "----------\n",
            "train Loss: 2.1556\n",
            "val Loss: 1.9853\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m m: init_weights(m, init_type\u001b[38;5;241m=\u001b[39minit_type))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m trained_model, best_train_loss, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#save results\u001b[39;00m\n\u001b[0;32m     36\u001b[0m results[init_type]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: lr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_val_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: best_val_loss})\n",
            "Cell \u001b[1;32mIn[17], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, num_epochs, optimizer, early_stopping_patience, visualize, l1_strength, l2_strength, lr, init_type)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#forward\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 49\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m#add in l1 and l2 regularization\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[15], line 76\u001b[0m, in \u001b[0;36mFashionMNISTResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 76\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_avg_pool(x)  \u001b[38;5;66;03m#apply global average pooling\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m#flatten\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mBasicResBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     31\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 32\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(out)\n\u001b[0;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lando\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import copy\n",
        "from collections import defaultdict\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "#initialize model\n",
        "def init_weights(m, init_type=\"random\"):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        if init_type == \"xavier\":\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        else:\n",
        "            nn.init.uniform_(m.weight, -0.1, 0.1)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "learning_rates = [.00001, .0001, .001]\n",
        "init_types = [\"random\", \"xavier\"]\n",
        "results = defaultdict(list)\n",
        "my_activation = \"relu\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for init_type in init_types:\n",
        "    for lr in learning_rates:\n",
        "        model = FashionMNISTResNet(input_shape=1, channels=[32, 32], output_shape=10, activation=my_activation, num_layers=2, dropout=.15)\n",
        "        model.apply(lambda m: init_weights(m, init_type=init_type))\n",
        "\n",
        "        #train model\n",
        "        trained_model, best_train_loss, best_val_loss = train_model(model, {'train': train_dataloader, 'val': val_dataloader},\n",
        "                                                   criterion, optimizer='adam',\n",
        "                                                   num_epochs=30, early_stopping_patience=5, visualize=True, lr=lr, init_type=init_type)\n",
        "\n",
        "        #save results\n",
        "        results[init_type].append({'lr': lr, 'best_val_loss': best_val_loss})\n",
        "\n",
        "#visualize\n",
        "for init_type in init_types:\n",
        "    lrs = [result['lr'] for result in results[init_type]]\n",
        "    losses = [result['best_val_loss'] for result in results[init_type]]\n",
        "    plt.plot(lrs, losses, label=f\"{init_type} init\")\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Learning Rate vs. Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b73161af",
      "metadata": {},
      "source": [
        "Hyperparameter Tuning 1\n",
        "\n",
        "I did explore this hyperparameter with more epochs, but it took a long time to run so after getting an idea of how the results looked. I'm taking it down to 2 epochs because I think that should still do an ok job capturing the effects of the l1 and l2 grid search regularization. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68890608",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "lr = 0.0001\n",
        "init_type = 'xavier'\n",
        "\n",
        "\n",
        "#hyperparameters for grid search\n",
        "l1_values = np.logspace(-4, -1, 10)\n",
        "l2_values = np.logspace(-4, -1, 10)\n",
        "\n",
        "results = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "for l1_strength in l1_values:\n",
        "    print(f\"Training with L1 strength: {l1_strength}\")\n",
        "    for l2_strength in l2_values:\n",
        "        print(f\"Training with L2 strength: {l2_strength}\")\n",
        "        model = FashionMNISTResNet(input_shape=1, channels=[64, 64], output_shape=10, num_layers=2, activation=my_activation, dropout=0)  \n",
        "        model.apply(lambda m: init_weights(m, init_type='xavier'))\n",
        "\n",
        "        #train model with L1 regularization\n",
        "        trained_model, train_loss, val_loss = train_model(model, {'train': train_dataloader, 'val': val_dataloader},\n",
        "                                                          criterion, optimizer='adam', num_epochs=2, lr=lr, init_type=init_type, l1_strength=l1_strength, early_stopping_patience=5, visualize=False)\n",
        "\n",
        "        #store results\n",
        "        results[l1_strength][l2_strength]['train_loss'] = train_loss\n",
        "        results[l1_strength][l2_strength]['val_loss'] = val_loss\n",
        "\n",
        "#convert results to numpy arrays for plotting\n",
        "train_losses = np.array([[results[l1][l2]['train_loss'] for l2 in l2_values] for l1 in l1_values])\n",
        "val_losses = np.array([[results[l1][l2]['val_loss'] for l2 in l2_values] for l1 in l1_values])\n",
        "\n",
        "#plotting\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "c1 = ax[0].imshow(train_losses, cmap='viridis', aspect='auto')\n",
        "ax[0].set_title('Training Loss')\n",
        "fig.colorbar(c1, ax=ax[0])\n",
        "\n",
        "c2 = ax[1].imshow(val_losses, cmap='viridis', aspect='auto')\n",
        "ax[1].set_title('Validation Loss')\n",
        "fig.colorbar(c2, ax=ax[1])\n",
        "\n",
        "#plot ratio or difference\n",
        "ratio = val_losses / train_losses\n",
        "c3 = ax[2].imshow(ratio, cmap='viridis', aspect='auto')\n",
        "ax[2].set_title('Validation/Training Loss Ratio')\n",
        "fig.colorbar(c3, ax=ax[2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3404a973",
      "metadata": {},
      "source": [
        "Hyperparameter Tuning 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1758d6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "#10 values for dropout\n",
        "dropout_values = np.linspace(0, 0.9, 10)  \n",
        "results = defaultdict(dict)  \n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    #init based on hyperparameter choice 2\n",
        "    model = FashionMNISTResNet(input_shape=1, channels=[96, 96, 96], output_shape=10, num_layers=2, activation='sigmoid', dropout=dropout_rate)\n",
        "    model.apply(lambda m: init_weights(m, init_type='xavier')) \n",
        "\n",
        "    optimizer = 'rmsprop'\n",
        "\n",
        "    #train\n",
        "    trained_model, train_loss, val_loss = train_model(\n",
        "        model,\n",
        "        {'train': train_dataloader, 'val': val_dataloader},  \n",
        "        criterion,\n",
        "        optimizer=optimizer,\n",
        "        num_epochs=10,\n",
        "        early_stopping_patience=5,\n",
        "        visualize=False,\n",
        "        l1_strength=0.0,\n",
        "        l2_strength=0.0,\n",
        "    )\n",
        "\n",
        "    #save results\n",
        "    results[dropout_rate]['train_loss'] = train_loss\n",
        "    results[dropout_rate]['val_loss'] = val_loss\n",
        "\n",
        "dropout_rates = np.array(list(results.keys()))\n",
        "train_losses = np.array([results[rate]['train_loss'] for rate in dropout_rates])\n",
        "val_losses = np.array([results[rate]['val_loss'] for rate in dropout_rates])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "#training loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(dropout_rates, train_losses, marker='o', label='Training Loss')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs. Dropout Rate')\n",
        "plt.legend()\n",
        "\n",
        "#validation loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(dropout_rates, val_losses, marker='o', color='r', label='Validation Loss')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss vs. Dropout Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#plotting the ratio\n",
        "ratio = val_losses / train_losses \n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(dropout_rates, ratio, marker='o', color='g', label='Val/Train Loss Ratio')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Ratio')\n",
        "plt.title('Validation/Training Loss Ratio vs. Dropout Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a60a61",
      "metadata": {},
      "source": [
        "Hyperparameter Tuning 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed67e713",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "#10 values for dropout\n",
        "dropout_values = np.linspace(0, 0.9, 10)  \n",
        "results = defaultdict(dict)  \n",
        "\n",
        "for dropout_rate in dropout_values:\n",
        "    #init based on hyperparameter choice 2\n",
        "    model = FashionMNISTResNet(input_shape=1, channels=[96, 96, 96], output_shape=10, num_layers=2, activation='relu', dropout=dropout_rate)\n",
        "    model.apply(lambda m: init_weights(m, init_type='xavier'))  \n",
        "\n",
        "    optimizer = 'adam'\n",
        "\n",
        "    #train\n",
        "    trained_model, train_loss, val_loss = train_model(\n",
        "        model,\n",
        "        {'train': train_dataloader, 'val': val_dataloader},  \n",
        "        criterion,\n",
        "        optimizer=optimizer,\n",
        "        num_epochs=10,\n",
        "        early_stopping_patience=5,\n",
        "        visualize=False,\n",
        "        l1_strength=0.0,\n",
        "        l2_strength=0.0,\n",
        "    )\n",
        "\n",
        "    #save results\n",
        "    results[dropout_rate]['train_loss'] = train_loss\n",
        "    results[dropout_rate]['val_loss'] = val_loss\n",
        "\n",
        "dropout_rates = np.array(list(results.keys()))\n",
        "train_losses = np.array([results[rate]['train_loss'] for rate in dropout_rates])\n",
        "val_losses = np.array([results[rate]['val_loss'] for rate in dropout_rates])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "#training loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(dropout_rates, train_losses, marker='o', label='Training Loss')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs. Dropout Rate')\n",
        "plt.legend()\n",
        "\n",
        "#validation loss plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(dropout_rates, val_losses, marker='o', color='r', label='Validation Loss')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss vs. Dropout Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#plotting the ratio\n",
        "ratio = val_losses / train_losses \n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.plot(dropout_rates, ratio, marker='o', color='g', label='Val/Train Loss Ratio')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('Ratio')\n",
        "plt.title('Validation/Training Loss Ratio vs. Dropout Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfc5b365",
      "metadata": {},
      "source": [
        "# Bonus assignment\n",
        "\n",
        "`+5 bonus points`\n",
        "\n",
        "`You DO NOT need to do this if you don't want to`\n",
        "\n",
        "* Once the data is collected, this HW should be quite easy, since most of the code can be recycled from the labs & textbook.\n",
        "\n",
        "* Do this in a file called `bonus.ipynb`, have it save its results to a folder \"data\"\n",
        "\n",
        "`Data collection`\n",
        "\n",
        "* Develope a text based classification data-set:\n",
        "* Use the Wikipedia API to search for articles to generate the data-set\n",
        "* Select a set of highly different topics (i.e. labels), for example,\n",
        "  * multi-class case: y=(pizza, oak_trees, basketball, ... , etc)=(0,1,2, ... , N-1)\n",
        "  * You don't have to use these, you can use whatever labels you want\n",
        "  * `Have AT LEAST 10 labels.`\n",
        "  * The more different the topics, the easier the classification task should be\n",
        "* Search for Wikipedia pages about these topics and harvest the text from the pages.\n",
        "* Do some basic text cleaning as needed.\n",
        "  * e.g. use the NLTK sentence tokenizer to break the text into sentences.\n",
        "  * Then form chunks of text that are five sentences long as your \"inputs\".\n",
        "* The \"label\" for these chunks will be the search label used to find the text.\n",
        "* The data set will not be perfect.\n",
        "  * There will be chunks of text that are not related to the topic (i.e. noise).\n",
        "  * However that is just something we have to live with.\n",
        "* **Important**: Always start small when writing & debugging THEN scale up.\n",
        "* The more chunks of text you have the better.\n",
        "  * Save the text and labels to the same format used by the textbook, that way you can recycle your lab code seamlessly.\n",
        "* `Optional practice`: You can also \"tag\" each chunk of text with an associated \"compound\" sentiment score computed using the NLTK sentiment analysis. From this you can train a regression model in part-2. This is somewhat silly, and is just for educational purposes, since your using a model output to train another model.\n",
        "\n",
        "`Model training`\n",
        "\n",
        "* Repeat the model training and hyper-parameter tuning exercise for MNIST, but with your text.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
